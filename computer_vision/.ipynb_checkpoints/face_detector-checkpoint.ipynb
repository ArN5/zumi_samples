{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<img src=\"../Data/images/ZumiHeader.png\" width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# How does Zumi see?\n",
    "\n",
    "<font size =3> Self-driving cars need a lot more than just obstacle detection sensors. Human drivers have eyes and ears that help us see potential dangers up ahead that maybe a proximity detector can't detect. We can also tell the different between pedestrians, cyclists, and other cars. What else do self-driving cars need to navigate our world?\n",
    "\n",
    "Watch [this](https://www.youtube.com/watch?v=wuhbqcMzOaw) video to see it in action.\n",
    "\n",
    "In this lesson you are going to learn how to access the camera, take pictures, and show video. </font>\n",
    "\n",
    "## Take a Selfie\n",
    "\n",
    "<font size =3> First up: use Zumi's camera to take a picture and display it on the screen! </font>\n",
    "\n",
    "<img src=\"../Data/images/zumi_camera.jpg\" width=500>\n",
    "\n",
    "### Import libraries\n",
    "<font size =3> Import the necessary libraries and create camera objects. </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from zumi.util.camera import Camera\n",
    "from zumi.util.screen import Screen\n",
    "from zumi.util.vision import Vision\n",
    "from zumi.zumi import Zumi\n",
    "import cv2\n",
    "import IPython.display\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "\n",
    "screen = Screen()\n",
    "camera = Camera()\n",
    "vision = Vision()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PiCamera\n",
      "Closing PiCamera\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gray' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6735ccb2684f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;31m#show the image taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/zumi/util/vision.py\u001b[0m in \u001b[0;36mfind_face\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0msigns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_cascade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaleFactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminNeighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminSize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCASCADE_SCALE_IMAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msigns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m#draw a bounding box on the stop sign found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gray' is not defined"
     ]
    }
   ],
   "source": [
    "camera = Camera()\n",
    "camera.start_camera()\n",
    "\n",
    "try: \n",
    "    #we do a for loop so that we only take 30 pictures\n",
    "    for i in range(30):\n",
    "        frame = camera.capture()\n",
    "        vision.find_face(frame)\n",
    "        #show the image taken\n",
    "        IPython.display.display(Image.fromarray(frame))\n",
    "        IPython.display.clear_output(wait=True) \n",
    "finally:\n",
    "    camera.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<font size =3> Just like taking an actual picture, this code has a countdown so you can be prepared.\n",
    "\n",
    "In the code below, the camera is turned on and then the countdown begins. There is a one second delay with <font face=\"Courier\">time.sleep(1)</font> so that there is a one second pause between each number. The rest of the code is commented so that you can see what each line of code does.\n",
    "\n",
    "Get ready to see yourself on the Zumi screen! For multiple pictures, run this cell multiple times. </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Cheese! ðŸ“¸ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "camera.start_camera() # Turn on the camera\n",
    "\n",
    "print(\"3...\")\n",
    "screen.draw_text(\"    3...\")\n",
    "time.sleep(1)\n",
    "print(\"2...\")\n",
    "screen.draw_text(\"    2...\")\n",
    "time.sleep(1)\n",
    "print(\"1...\")\n",
    "\n",
    "screen.draw_text(\"    1...\")\n",
    "time.sleep(1)\n",
    "screen.draw_text(\"    Cheese!\")\n",
    "\n",
    "\n",
    "image = camera.capture() # Take a picture\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # Convert it to gray\n",
    "\n",
    "small = cv2.resize(gray, (128,64)) # Resize it to fit the screen\n",
    "    \n",
    "screen.draw_image(Image.fromarray(small).convert('1')) # show the picture! \n",
    "\n",
    "camera.close() # Make sure to close the camera stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Resolution\n",
    "<font size =3> You probably have noticed that the picture is very pixelated and hard to see. That is because the OLED screen is only 128 pixels wide and 64 pixels tall! How many pixels total does the OLED have? </font>\n",
    "\n",
    "### Displaying images  in Jupyter\n",
    "\n",
    "<font size =3> Instead of showing your picture on the Zumi screen, display it right here in the Jupyter Notebook. As a bonus, it will appear in color! </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "camera.start_camera()\n",
    "print(\"3...\")\n",
    "screen.draw_text(\"3...\")\n",
    "time.sleep(1)\n",
    "print(\"2...\")\n",
    "screen.draw_text(\"2...\")\n",
    "time.sleep(1)\n",
    "print(\"1...\")\n",
    "screen.draw_text(\"1...\")\n",
    "time.sleep(1)\n",
    "screen.draw_text(\"Cheese!\")\n",
    "\n",
    "frame = camera.capture()\n",
    "IPython.display.display(Image.fromarray(frame))\n",
    "IPython.display.clear_output(wait=True) \n",
    "time.sleep(5)\n",
    "        \n",
    "camera.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing color\n",
    "<font size =3> One neat thing you can do is change the color space of the image Zumi takes. </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.start_camera()\n",
    "frame = camera.capture()\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # Convert it to gray\n",
    "IPython.display.display(Image.fromarray(gray))\n",
    "camera.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.start_camera()\n",
    "frame = camera.capture()\n",
    "invert = cv2.bitwise_not(frame) # invert the colors\n",
    "IPython.display.display(Image.fromarray(invert))\n",
    "camera.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.start_camera()\n",
    "frame = camera.capture()\n",
    "hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) # Convert it to HSV, hue saturation and value\n",
    "IPython.display.display(Image.fromarray(hsv))\n",
    "camera.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.start_camera()\n",
    "frame = camera.capture()\n",
    "#y Luminance, Cb and Cr are chroma.\n",
    "ycrcb = cv2.cvtColor(frame, cv2.cv2.COLOR_BGR2YCrCb) # Convert it to YCrCb\n",
    "IPython.display.display(Image.fromarray(ycrcb))\n",
    "camera.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.start_camera()\n",
    "frame = camera.capture()\n",
    "#LAB stands for Lightness,\n",
    "#A stands for color component Green to magenta\n",
    "#Color component from Blue to Yellow\n",
    "LAB = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB) \n",
    "IPython.display.display(Image.fromarray(LAB))\n",
    "camera.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing resolution\n",
    "<font size =3> Everytime you take a picture the default resolution is width = 160 and height = 120 you can change the resolution like this. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new desired width resolution and height resolution\n",
    "#we will make the image smaller\n",
    "width = 80\n",
    "height = 64\n",
    "\n",
    "#you have to pass in the new resolution into the camera object\n",
    "camera = Camera(width,height)\n",
    "\n",
    "camera.start_camera()\n",
    "frame = camera.capture()\n",
    "IPython.display.display(Image.fromarray(frame))\n",
    "camera.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can double the resolution if you would like\n",
    "#but the image will take longer to load\n",
    "width = 320\n",
    "height = 240\n",
    "\n",
    "camera = Camera(width,height)\n",
    "camera.start_camera()\n",
    "frame = camera.capture()\n",
    "IPython.display.display(Image.fromarray(frame))\n",
    "camera.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large images\n",
    "\n",
    "<font size =3> Here we will take a full resolution image, you will notice that Zumi will take longer processing this large file</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will take way longer but has the highest resolution\n",
    "width = 1296\n",
    "height = 976\n",
    "\n",
    "camera = Camera(width,height)\n",
    "camera.start_camera()\n",
    "frame = camera.capture()\n",
    "IPython.display.display(Image.fromarray(frame))\n",
    "camera.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Video\n",
    "\n",
    "<font size =3> A video is just a series of pictures one after the other. In order to display a video in Jupyter, you take pictures inside of a <font face=\"Courier\">for </font>loop.\n",
    "<font size =3>We will take 30 frames and display them</font>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "camera = Camera()\n",
    "camera.start_camera()\n",
    "\n",
    "try: \n",
    "    #we do a for loop so that we only take 30 pictures\n",
    "    for i in range(30):\n",
    "        frame = camera.capture()\n",
    "        #show the image taken\n",
    "        IPython.display.display(Image.fromarray(frame))\n",
    "        IPython.display.clear_output(wait=True) \n",
    "finally:\n",
    "    camera.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warped video\n",
    "\n",
    "<font size =3> Here we will warp the image in order to make our faces look funny</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = Camera()\n",
    "camera.start_camera()\n",
    "\n",
    "try: \n",
    "    #we do a for loop so that we only take 100 pictures\n",
    "    for i in range(100):\n",
    "        frame = camera.capture()\n",
    "        frame = vision.warp_frame(frame)\n",
    "        #show the image taken\n",
    "        IPython.display.display(Image.fromarray(frame))\n",
    "        IPython.display.clear_output(wait=True) \n",
    "finally:\n",
    "    camera.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting color\n",
    "<font size =3> You can use these color space changes to detect certain colors. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = Camera()\n",
    "camera.start_camera()\n",
    "\n",
    "try: \n",
    "    #we do a for loop so that we only take 30 pictures\n",
    "    for i in range(100):\n",
    "        frame = camera.capture()\n",
    "        #show the image taken\n",
    "\n",
    "        vision.find_orange_object(frame)\n",
    "        \n",
    "        IPython.display.display(Image.fromarray(frame))\n",
    "        IPython.display.clear_output(wait=True) \n",
    "finally:\n",
    "    camera.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digital gimbal\n",
    "<font size =3> Here we will rotate the image in order to keep the image \"level\" with the ground</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zumi = Zumi()\n",
    "camera = Camera()\n",
    "camera.start_camera()\n",
    "\n",
    "#for this grab you Zumi and tilt it left to right\n",
    "#the image will try to stay \"flat\" similar to a \n",
    "try: \n",
    "    #we do a for loop so that we only take 30 pictures\n",
    "    for i in range(100):\n",
    "        roll = zumi.update_angles()[3]\n",
    "        frame = camera.capture()\n",
    "        #we do -1 times the roll since the image is mirrored\n",
    "        rotated_frame = vision.rotate_frame(frame,-1*roll)\n",
    "        IPython.display.display(Image.fromarray(rotated_frame))\n",
    "        IPython.display.clear_output(wait=True) \n",
    "\n",
    "finally:\n",
    "    camera.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twirling the camera\n",
    "<font size =3> Here you can try some of the things you have learned use one the sensors to make the camera tilt.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zumi = Zumi()\n",
    "camera = Camera()\n",
    "camera.start_camera()\n",
    "\n",
    "try: \n",
    "    for i in range(100):\n",
    "        #you code here!\n",
    "        \n",
    "        #use any of the sensor inputs to modify the\n",
    "        #angle that the image taken is rotated\n",
    "        #here is an example below\n",
    "        angle = zumi.update_angles()[2]\n",
    "        frame = camera.capture()\n",
    "        rotated_frame = vision.rotate_frame(frame,angle)\n",
    "        IPython.display.display(Image.fromarray(rotated_frame))\n",
    "        IPython.display.clear_output(wait=True) \n",
    "finally:\n",
    "    camera.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
